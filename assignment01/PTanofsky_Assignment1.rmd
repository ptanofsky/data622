---
title: "DATA 622 Assignment 1"
subtitle: "CUNY: Spring 2021"
author: "Philip Tanofsky"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: pdf_document
---

# Introduction

The purpose of this project is to apply logistic regression approaches to the Palmer Penguin data set available at https://allisonhorst.github.io/palmerpenguins/articles/intro.html. The first approach performs binary logistic regression on the dataset in order to predict a species or not of the penguin subjects. The second approach utilizes all three species to perform a multinomial logistic regression in order to predict the species of penguin subjects. While the primary goal of the logistic regression is to predict the penguin species, statistical interpretation also presents the context for the prediction models.

Data – 622
Homework # 1
Due date Feb 19, 2021- 11:59 EST
Let’s use the Penguin dataset for our assignment. To learn more about the dataset, please visit:
https://allisonhorst.github.io/palmerpenguins/articles/intro.html
For this assignment, let us use ‘species’ as our outcome or the dependent variable.
1. Logistic Regression with a binary outcome. (40)
a. The penguin dataset has ‘species’ column. Please check how many categories
you have in the species column. Conduct whatever data manipulation you need to do to be able to build a logistic regression with binary outcome. Please explain your reasoning behind your decision as you manipulate the outcome/dependent variable (species).
b. Please make sure you are evaluating the independent variables appropriately in deciding which ones should be in the model.
c. Provide variable interpretations in your model.
2. For your model from #1, please provide: AUC, Accuracy, TPR, FPR, TNR, FNR (20)
3. Multinomial Logistic Regression. (40)
a. Please fit it a multinomial logistic regression where your outcome variable is
‘species’.
b. Please be sure to evaluate the independent variables appropriately to fit your
best parsimonious model.
c. Please be sure to interpret your variables in the model.
4. Extra credit: what would be some of the fit statistics you would want to evaluate for your model in question #3? Feel free to share whatever you can provide. (10)

```{r warning=F, message=F}
# Import required R libraries
library(palmerpenguins)
library(dplyr)
library(ggplot2)
library(tidyr)
library(caret)
library(MASS)
library(pROC)
library(nnet) # Used for multinomial logistic regression
library(mlogit)
library(stargazer)
library(popbio)
# Set theme, based on the Penguin vignettes
theme_set(theme_minimal())
```

The palmer penguins dataset consists of 8 variables, 7 independent variables and 1 dependent variable (species).

## Variables

- species: species of the penguin observed (dependent variable)

- island: island of penguin's inhabitance

- bill_length_mm: penguin bill length in millimeters

- bill_depth_mm: penguin bill depth in millimeters

- flipper_length_mm: penguin flipper length in millimeters

- body_mass_g: penguin body mass in grams

- sex: penguin sex

- year: year of observation

## EDA

Initial data summary and exploratory data analysis.

```{r warning=F,message=F}
ds <- penguins

head(ds)

summary(ds)

dim(ds)

glimpse(ds)

visdat::vis_dat(ds)
```

Initial summary outputs show 344 instances of the 8 variables. The final graph indicates the missing values among the 8 variables. Variables with missing values include $sex$, $bill_length_mm$, $bill_depth_mm$, $flipper_length_mm$ and $body_mass_g$.

```{r warning=F,message=F}
# Penguins data has three factor variables
ds %>%
  dplyr::select(where(is.factor)) %>%
  glimpse()

# Count penguins for each species / island
ds %>%
  count(species, island, .drop=F)

ggplot(ds, aes(x = island, fill = species)) +
  geom_bar(alpha = 0.8) +
  scale_fill_manual(values = c("darkorange", "purple", "cyan4"),
                    guide = F) +
  theme_minimal() +
  facet_wrap(~species, ncol = 1) +
  coord_flip()
```

The above plot indicates the population of penguin species based on island. Interesting finding that Chinstrap are only observed on Dream island and Gentoo are only observed on Biscoe island, while the Adelie species are observed on all three islands in the study.

```{r warning=F,message=F}
# Count penguins for each species / sex
ds %>%
  count(species, sex, .drop = F)

ggplot(ds, aes(x = sex, fill = species)) +
  geom_bar(alpha = 0.8) +
  scale_fill_manual(values = c("darkorange", "purple", "cyan4"),
                    guide = F) +
  theme_minimal() +
  facet_wrap(~species, ncol = 1) +
  coord_flip()
```

The above breakdown of penguin species by sex shows an expected ratio of near 50-50 for each species.

```{r warning=F,message=F}
# Penguins data also has four continuous variables, making six unique scatterplots
ds %>%
  dplyr::select(body_mass_g, ends_with("_mm")) %>%
  glimpse()

# Scatterplot example 1: penguin flipper length versus body mass
ggplot(data = penguins, aes(x = flipper_length_mm, y = body_mass_g)) +
  geom_point(aes(color = species,
                 shape = species),
             size = 2) +
  scale_color_manual(values = c("darkorange", "darkorchid", "cyan4"))
```

The above scatterplot of body mass shows a strong similarity between the species Adelie and Chinstrap with a clear difference from Gentoo. A valuable observation in regards to the binary logistic regression model.

```{r warning=F, message=F}
ds %>%
  dplyr::select(species, body_mass_g, ends_with("_mm")) %>%
  GGally::ggpairs(aes(color = species)) +
  scale_color_manual(values = c("darkorange","purple","cyan4")) +
  scale_fill_manual(values = c("darkorange","purple","cyan4"))
```

The above plot shows the additional strong similarities between the Adelie and Chinstrap species as compared to the Gentoo species.

## Model Definitions

Prep dataset for logistic regression. First step is to remove rows containing an NA.

```{r}
# Create dataset for binary logistic regression: species Gentoo or Not
data_binary <- penguins

# Only use complete instances ... actually come back to this as I don't want to exclude because of sex 11 NAs
train_data_binary <- na.omit(data_binary)

dim(train_data_binary)
```

Based on the result, 11 rows are removed, which would equal the number of NAs in variable $sex$.

# Binary Logistic Regression

The following approach attempts to construct a logistic regression model based on a binary outcome. As the penguins dataset is based on a dependent variable (species) containing three values, a dummy variable $Gentoo$ is defined to identify penguins of the species Gentoo or of the other two values (Adelie and Chinstrap). Based on the exploratory data analysis indicating independent variable overlap for body mass, bill depth, and flipper length between the Adelie and Chinstrap species, the decision was made to group these two species based on the similarities.

```{r}
# Create new column
train_data_binary$gentoo <- ifelse(train_data_binary$species=="Gentoo", 1, 0)

summary(train_data_binary)
```

With the derived dummy variable $Gentoo$, the variable $species$ is removed from the initial dataset, so as not to impact the logistic regression models.

```{r}
# Drop species column, as now just using gentoo column as Y variable

drops <- c("species")
train_data_binary <- train_data_binary[ , !(names(train_data_binary) %in% drops)]

summary(train_data_binary)
```

In order to validate the models properly, the initial penguins dataset is partitioned into training data at 70% of the given dataset with the remaining 30% used as test data completely unseen by the model.

```{r warning=F}
set.seed(123)
trainIndex <-createDataPartition(train_data_binary$gentoo, p = 0.7, list = FALSE, times = 1)
train <- train_data_binary[trainIndex,]
test <- train_data_binary[-trainIndex,]
```

Three versions of a binary logistic regression model are constructed in order to evaluate the accuracy of each and also provide to narrow the model to the least number of variables to identify the most parsimomious model.

### Baseline Model

The first model uses all the available independent variables in order to define a baseline evaluation of the model.

```{r warning=F}
# All variables
model1 <- glm(gentoo ~ ., data = train, family = "binomial"(link="logit"))
#Accuracy 100%, AIC is 18
summary(model1)
```

Resulting AIC: `r model1$aic`.

### Stepwise Model

Next, the $stepAIC$ function is applied to the full model to determine the most predictive variables for the model.

```{r warning=F}
# All variables then applied with stepAIC
model2 <- glm(gentoo ~ ., data = train, family = "binomial"(link="logit")) %>% stepAIC(trace=F, direction ='both')
# Accuracy 100% an AIC is 6
summary(model2)
```

Resulting AIC: `r model2$aic`.

### Hand Selected Model

Finally, a hand-selected list of independent variables are chosen based on the evaluation of the exploratory data analysis.

```{r warning=F}
# Hand selected variables
model3 <- glm(gentoo ~ island + bill_depth_mm + flipper_length_mm + body_mass_g, data = train, family = "binomial"(link="logit"))
# Accuracy 100%, AIC is 12
summary(model3)
```

Resulting AIC: `r model3$aic`.

### Make predictions

Predictions are performed on the test dataset based on the three above binary logistic regression models.

```{r warning=F, message=F}
## use the test data set to make predictions for the 3 models
mod1.predict.probs <- predict.glm(model1, type="response", newdata=test)
mod1.predict.manual <- ifelse(mod1.predict.probs > 0.5, '1','0')
attach(test)

mod2.predict.probs <- predict.glm(model2, type="response", newdata=test)
mod2.predict.manual <- ifelse(mod2.predict.probs > 0.5, '1','0')
attach(test)

mod3.predict.probs <- predict.glm(model3, type="response", newdata=test)
mod3.predict.manual <- ifelse(mod3.predict.probs > 0.5, '1','0')
attach(test)
```

### Model Visualizations

Plots of the data to visualize the independent variable's value compared to the logit function of the dependent variable.

First, plot the variable $flipper_length_mm$ against the logit value of the $Gentoo$ result.

```{r warning=F,message=F}
# Plot the dependent variable interpretation
# https://sites.google.com/site/daishizuka/toolkits/plotting-logistic-regression-in-r

# plot with flipper_length_mm on x-axis and Gentoo species (0 or 1) on y-axis
plot(flipper_length_mm,gentoo,xlab="flipper_length_mm",ylab="Probability of Gentoo")
g=glm(gentoo ~ flipper_length_mm, data = train, family = "binomial"(link="logit"))
curve(predict(g,data.frame(flipper_length_mm=x),type="resp"),add=TRUE)
```

Second, plot the variable $bill_depth_mm$ against the logit value of the $Gentoo$ result.

```{r warning=F,message=F}
# plot with bill_depth_mm on x-axis and Gentoo species (0 or 1) on y-axis
plot(bill_depth_mm,gentoo,xlab="bill_depth_mm",ylab="Probability of Gentoo")
g=glm(gentoo ~ bill_depth_mm, data = train, family = "binomial"(link="logit"))
curve(predict(g,data.frame(bill_depth_mm=x),type="resp"),add=TRUE)

# plot using another function
logi.hist.plot(flipper_length_mm,gentoo,boxp=FALSE,type="hist",col="gray")
```

Third plot above was just an attempt to use another library function for plotting the data against the logit function.

### Model 1 Results

The baseline model shows: 

- Accuracy: 1 or 100%

- Area Under the Curve: 1.0

- True Positive Rate (Sensitivity): 1.0

- True Negative Rate (Specificity: 1.0

- False Negative Rate (Miss Rate: 1-TPR): 0

- False Positive Rate (Fall-out: 1-TNR): 0

```{r warning=F,message=F}
# Model1
# now can use the caret function
cm.var <- caret::confusionMatrix(factor(mod1.predict.manual), factor(test$gentoo), positive='1')
cm.var$table

# print metrics
mod1.CMmetrics <- c(cm.var$overall[c(1)], cm.var$byClass[c(1,2,5,6,7)])
mod1.CMmetrics

# ROC and AUC 
par(pty="s")
roc.stepwise <- roc(train$gentoo, model1$fitted.values, plot=TRUE, print.auc=TRUE)
```

### Model 2 Results

The $stepAIC$ model shows:

- Accuracy: 1 or 100%

- Area Under the Curve: 1.0

- True Positive Rate (Sensitivity): 1.0

- True Negative Rate (Specificity: 1.0

- False Negative Rate (Miss Rate: 1-TPR): 0

- False Positive Rate (Fall-out: 1-TNR): 0

```{r warning=F,message=F}
# Model2
# now can use the caret function
cm.var <- caret::confusionMatrix(factor(mod2.predict.manual), factor(test$gentoo), positive='1')
cm.var$table

# print metrics
mod2.CMmetrics <- c(cm.var$overall[c(1)], cm.var$byClass[c(1,2,5,6,7)])
mod2.CMmetrics

# ROC and AUC 
par(pty="s")
roc.stepwise <- roc(train$gentoo, model2$fitted.values, plot=TRUE, print.auc=TRUE)
```

### Model 3 Results

The hand-selected model shows:

- Accuracy: 1 or 100%

- Area Under the Curve: 1.0

- True Positive Rate (Sensitivity): 1.0

- True Negative Rate (Specificity: 1.0

- False Negative Rate (Miss Rate: 1-TPR): 0

- False Positive Rate (Fall-out: 1-TNR): 0

```{r warning=F,message=F}
# Model3
# now can use the caret function
cm.var <- caret::confusionMatrix(factor(mod3.predict.manual), factor(test$gentoo), positive='1')
cm.var$table

# print metrics
mod3.CMmetrics <- c(cm.var$overall[c(1)], cm.var$byClass[c(1,2,5,6,7)])
mod3.CMmetrics

# ROC and AUC 
par(pty="s")
roc.stepwise <- roc(train$gentoo, model3$fitted.values, plot=TRUE, print.auc=TRUE)
```

Looking at the summary results for the three models attempting to identify Gentoo species or not, I decided to make the goal a bit more difficult as Adelie species appears on all three islands, and statistically, the Adelie species does overlap with Chinstrap, I decided to create logistic regression models to identify Adelie instead of Gentoo.

The first model uses the same baseline model approach as above including all independent variables. The second model re-uses the $stepAIC$ approach to algorithmically select the best independent variables.

```{r warning=F,message=F}
# Create dataset for binary logistic regression: species Adelie or Not
data_binary <- penguins

# Only use complete instances ... actually come back to this as I don't want to exclude because of sex 11 NAs
train_data_binary <- na.omit(data_binary)

train_data_binary$adelie <- ifelse(train_data_binary$species=="Adelie", 1, 0)

summary(train_data_binary)

drops <- c("species")
train_data_binary <- train_data_binary[ , !(names(train_data_binary) %in% drops)]

set.seed(123)
trainIndex <-createDataPartition(train_data_binary$adelie, p = 0.7, list = FALSE, times = 1)
train <- train_data_binary[trainIndex,]
test <- train_data_binary[-trainIndex,]

# All variables
model1_ad <- glm(adelie ~ ., data = train, family = "binomial"(link="logit"))
summary(model1_ad)

# All variables then applied with stepAIC
model2_ad <- glm(adelie ~ ., data = train, family = "binomial"(link="logit")) %>% stepAIC(trace=F, direction ='both')
summary(model2_ad)

## use the test data set to make predictions for the 3 models
mod1_ad.predict.probs <- predict.glm(model1_ad, type="response", newdata=test)
mod1_ad.predict.manual <- ifelse(mod1_ad.predict.probs > 0.5, '1','0')
attach(test)

mod2_ad.predict.probs <- predict.glm(model2_ad, type="response", newdata=test)
mod2_ad.predict.manual <- ifelse(mod2_ad.predict.probs > 0.5, '1','0')
attach(test)

# Model1
# now can use the caret function
cm.var <- caret::confusionMatrix(factor(mod1_ad.predict.manual), factor(test$adelie), positive='1')
cm.var$table

# print metrics
mod1_ad.CMmetrics <- c(cm.var$overall[c(1)], cm.var$byClass[c(1,2,5,6,7)])
mod1_ad.CMmetrics

# ROC and AUC 
par(pty="s")
roc.stepwise <- roc(train$adelie, model1_ad$fitted.values, plot=TRUE, print.auc=TRUE)
```


The baseline model shows:

- Accuracy: 0.9797980 or ~98%

- Area Under the Curve: 1.0

- True Positive Rate (Sensitivity): 0.9534884

- True Negative Rate (Specificity: 1.0

- False Negative Rate (Miss Rate: 1-TPR): 0.0465116

- False Positive Rate (Fall-out: 1-TNR): 0

```{r warning=F,message=F}
# Model2
# now can use the caret function
cm.var <- caret::confusionMatrix(factor(mod2_ad.predict.manual), factor(test$adelie), positive='1')
cm.var$table

# print metrics
mod2_ad.CMmetrics <- c(cm.var$overall[c(1)], cm.var$byClass[c(1,2,5,6,7)])
mod2_ad.CMmetrics

# ROC and AUC 
par(pty="s")
roc.stepwise <- roc(train$adelie, model2_ad$fitted.values, plot=TRUE, print.auc=TRUE)
```

The $stepAIC$ model shows:

- Accuracy: 0.9797980 or ~98%

- Area Under the Curve: 1.0

- True Positive Rate (Sensitivity): 0.9534884

- True Negative Rate (Specificity: 1.0

- False Negative Rate (Miss Rate: 1-TPR): 0.0465116

- False Positive Rate (Fall-out: 1-TNR): 0

Interestingly, the $stepAIC$ did not perform at 100% accuracy. The $stepAIC$ model indicates $bill_length_mm$, $bill_depth_mm$, and $body_mass_g$ are the three most predictive independent variables.

# Multinomial Logistic Regression

The following approach attempts to construct a multinomial logistic regression model based on a multivariate outcome. As the penguins dataset is based on a dependent variable (species) containing three values, these models attempt to predict the species of each penguin subject. 

```{r warning=F, message=F}
# Initial walk-through: https://stats.idre.ucla.edu/r/dae/multinomial-logistic-regression/

# Start with initial dateset
mlr_data <- penguins

summary(mlr_data)

mlr_data$species2 <- relevel(mlr_data$species, ref = "Gentoo")
test <- multinom(species2 ~ body_mass_g + bill_length_mm + bill_depth_mm + flipper_length_mm + island, data = mlr_data)

summary(test)

stargazer(test, type="text", out="test.htm")

test.rrr = exp(coef(test))
test.rrr

stargazer(test, type="text", coef=list(test.rrr), p.auto=FALSE, out="testrrr.htm")
```

```{r warning=F}
# Again with https://www.r-bloggers.com/2020/05/multinomial-logistic-regression-with-r/

index <- createDataPartition(mlr_data$species, p = .70, list = FALSE)
train <- mlr_data[index,]
test <- mlr_data[-index,]

# Set the reference 
train$species <- relevel(train$species, ref = "Adelie")

# Training the multinomial model
#multinom_model <- multinom(species ~ ., data = mlr_data)

multinom_model <- multinom(species ~ island + bill_depth_mm + bill_length_mm, data = mlr_data)

#multinom_model <- multinom(species ~ flipper_length_mm + body_mass_g, data = mlr_data)


#with flipper length, and with body mass, will also get to one hundred accuracy
# but these 3 are required for 100: island + bill_depth_mm + bill_length_mm

# Checking the model
summary(multinom_model)

z <- summary(multinom_model)$coefficients/summary(multinom_model)$standard.errors
z

p <- (1 - pnorm(abs(z), 0, 1)) * 2
p

# Convert the coefficients to odds by taking the exponential of the coefficients.
exp(coef(multinom_model))

head(pp <- fitted(multinom_model))

#dses <- data.frame(ses = c("low", "middle", "high"), write = mean(ml$write))
#predict(test, newdata = dses, "probs")

# What is this?
head(round(fitted(multinom_model), 2))

```

```{r warning=F}
# Predicting and validating the model

# Predicting the values for train dataset
train$speciesPredicted <- predict(multinom_model, newdata = train, "class")

# Building classification table
tab <- table(train$species, train$speciesPredicted)

# Calculating accuracy - sum of diagonal elements divided by total obs
round((sum(diag(tab))/sum(tab))*100,2)

# Predicting the class for test dataset
test$speciesPredicted <- predict(multinom_model, newdata = test, "class")

# Building classification table
tab <- table(test$species, test$speciesPredicted)
tab
```

### Attempt at Extra Credit

After some Internet searching, it appears there isn't much direction in how to measure model fit for multinomial logistic regression models. Pearson residual and Overdispersion are ways to measure the model. Approaches to comparing two or more models would include likelihood ratio test, wald test, cross validation and parallel lines assumption.

Sex doesn't matter, 
Considering that I'm grouping Orange and Purple, probably don't use bill_length_mm, as that one shows purple and green have similar distribution

# Conclusion


# Prompt

 
 
 Considers for multinomial
 wald test
 LR test: likelihood ratio
 Cross validation
 parallel lines assumption
 
 Ideas here: https://stats.stackexchange.com/questions/145203/how-to-assess-if-a-model-is-good-in-multinomial-logistic-regression