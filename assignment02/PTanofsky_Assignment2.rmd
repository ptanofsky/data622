---
title: "DATA 622 Assignment 2"
subtitle: "CUNY: Spring 2021"
author: "Philip Tanofsky"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: pdf_document
bibliography: bibliography.bib
---

# Introduction

The purpose of this project is to apply generative model approaches to the Palmer Penguin data set available at https://allisonhorst.github.io/palmerpenguins/articles/intro.html [@ppens]. The first approach performs linear discriminant analysis (LDA) on the dataset in order to predict the species of the penguin subjects. The second approach performs a quadratic discriminant analysis (QDA) in order to predict the species of penguin subjects. The final approach uses the Naive Bayes modeling approach to also predict the species of the penguin subjects. The exploratory data analysis informs the decisions of the predictor variables included for each generative model. A comparison of the models are presented in order to compare the accuracy of each.

```{r warning=F, message=F}
# Import required R libraries
library(palmerpenguins)
library(tidyverse)
library(caret)
library(MASS)
library(ggplot2)
library(mvtnorm)
library(e1071)
library(klaR)
library(pROC)
library(corrplot)
theme_set(theme_classic())
```

# Initial Data Inspection

```{r warning=F,message=F}
ds <- penguins

head(ds)

summary(ds)

dim(ds)
```

The palmer penguins dataset consists of 8 variables, 7 independent variables and 1 dependent variable (species).

## Variables

- species: species of the penguin observed (dependent variable)

- island: island of penguin's observation

- bill_length_mm: penguin bill length in millimeters

- bill_depth_mm: penguin bill depth in millimeters

- flipper_length_mm: penguin flipper length in millimeters

- body_mass_g: penguin body mass in grams

- sex: penguin sex

- year: year of observation

# Exploratory Data Analysis

For linear discriminant analysis, two assumptions are made about the data. One, the predictors are normally distributed, which means the data follows a Gaussian distribution for each class. Two, the classes have class-specific means but also have equal variance and covariance.

First step, confirm multivariate normal distribution. A density plot of the four continuous variables by species indicates the normal distribution for the class-specific plots.

```{r warning=F,message=F}
# Overlayed density plots
featurePlot(x = penguins[, 3:6],
            y = penguins$species,
            plot = "density",
            # Pass in options to xyplot() to
            # make it prettier
            scales = list(x = list(relation="free"),
                          y = list(relation="free")),
            adjust = 1.5,
            pch = "|",
            layout = c(2, 2),
            auto.key = list(columns = 3))
```

The variable $flipper\_length\_mm$ shows the clearest example of normal distribution by species class. The four density plots also indicate common evaluations between the Adelie and Chinstrap species for the independent variables $flipper\_length\_mm$, $body\_mass\_g$, and $bill\_depth\_mm$. The remaining continuous variable, $bill\_length\_mm$, shows an overlap between the Chinstrap and Gentoo species.

The scatterplot matrix of the continuous variables indicates the relationships between the independent variables for each of the three penguin species.

```{r warning=F,message=F}
# Use featurePlot
# https://topepo.github.io/caret/visualizations.html

# Scatterplot
featurePlot(x = penguins[, 3:6],
            y = penguins$species,
            plot = "pairs",
            # Add a key at the top
            auto.key = list(columns = 3))
```

The independent variable $bill\_length\_mm$ stands out by providing a clear distinction between the three penguin species when compared with any of the other three independent variables. As seen in the above scatterplot, when using any two of the other three independent variables, the plot results in a clear overlap of the Adelie and Chinstrap species, an expected result given the prior density plots.

So far, the independent variable $bill\_length\_mm$ is a prime candidate to be included in the generative models. The key will be identifying which of the other variables will provide additional significance to the model.

The following boxplots provide another perspective of the continuous variable relationships across the three species. As already noted, Adelie and Chinstrap show similar means and distributions for three of the four variables. The boxplot does indicate a few outliers across the variable values but nothing egregious.

```{r warning=F,message=F}
featurePlot(x = penguins[, 3:6], 
            y = penguins$species, 
            plot = "box", 
            ## Pass in options to bwplot() 
            scales = list(y = list(relation="free"),
                          x = list(rot = 90)),  
            layout = c(2,2), 
            auto.key = list(columns = 2))
```

With the first assumption confirmed, the second assumption is to confirm the similar covariance across the species classes. The following covariance checks further identify the relationship between the variables.

```{r warning=F,message=F}
# Covariance matrix
p_g <- penguins %>% filter(species == 'Gentoo')
cov_mat <- cov(p_g[,3:6],  use = "complete.obs")
round(cov_mat, 2)

p_a <- penguins %>% filter(species == 'Adelie')
cov_mat <- cov(p_a[,3:6],  use = "complete.obs")
round(cov_mat, 2)

p_c <- penguins %>% filter(species == 'Chinstrap')
cov_mat <- cov(p_c[,3:6],  use = "complete.obs")
round(cov_mat, 2)
```

Comparing the variance of each continuous independent variable across the three species classes, $body\_mass\_g$ shows the divergence in the variance evaluation, particularly for the Gentoo species. Then again, this variable is a weight measured in grams, so perhaps dividing each value by 1000 to measure in kilograms would make the variance seems less divergent. The prior density plot does show the wider distribution among Gentoo species for $body\_mass\_g$.

The covariance of $bill\_length\_mm$ and $bill\_depth\_mm$ denotes a low number, indicating a weak relationship. Two variables, $bill\_depth\_mm$ and $flipper\_length\_mm$, also show a comparatively low covariance. The pair of $bill\_length\_mm$ and $flipper\_length\_mm$ indicates a covariance higher than the aforementioned pairs, but the resulting values across the three species classes are much better than the other variable pairs.

Assessing the mean of each continuous independent variable for each species class, the variable $bill\_depth\_mm$ highlights the least difference in mean values of four variables. In fact, the difference in mean for Adelie and Chinstrap is one tenth of a millimeter.

```{r warning=F,message=F}
# Means
p_a[,3:6] %>% summarise_each(funs( mean( .,na.rm = TRUE)))
p_g[,3:6] %>% summarise_each(funs( mean( .,na.rm = TRUE)))
p_c[,3:6] %>% summarise_each(funs( mean( .,na.rm = TRUE)))
```

## Correlation matrix

Based on the covariance matrix, the correlation matrix should confirm the variable relationships as previously noted. Again, $bill\_length\_mm$ and $bill\_depth\_mm$ show the least correlation. Variables $body\_mass\_g$ and $flipper\_length\_mm$ have a high correlation.

```{r warning=F,message=F}
# Compute correlation matrix
cor_mat <- cor(penguins[,3:6],  use = "complete.obs")
round(cor_mat, 2)

corrplot(cor_mat, type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45)

```

## Categorical Variables

For comprehensive exploratory data analysis, the categorical independent variables are plotted and assessed.

The breakdown of penguin species by island indicates an uneven distribution by island. Gentoo only appear on Biscoe island, Chinstrap only appear on Dream, and Adelie appears on all three island under consideration, Torgensen, Dream and Biscoe.

```{r warning=F,message=F}
# Count penguins for each species / island
ggplot(ds, aes(x = island, fill = species)) +
  geom_bar(alpha = 0.8) +
  scale_fill_manual(values = c("darkorange", "purple", "cyan4"),
                    guide = F) +
  theme_minimal() +
  facet_wrap(~species, ncol = 1) +
  coord_flip()
```

The penguin category for sex shows a clear, even distribution by species with a few values missing for Adelie and Gentoo species.

```{r warning=F,message=F}
# Count penguins for each species / sex
ggplot(ds, aes(x = sex, fill = species)) +
  geom_bar(alpha = 0.8) +
  scale_fill_manual(values = c("darkorange", "purple", "cyan4"),
                    guide = F) +
  theme_minimal() +
  facet_wrap(~species, ncol = 1) +
  coord_flip()
```

The penguin category for year also indicates a relatively even distribution for each species.

```{r warning=F,message=F}
# Count penguins for each species / year
ggplot(ds, aes(x = year, fill = species)) +
  geom_bar(alpha = 0.8) +
  scale_fill_manual(values = c("darkorange", "purple", "cyan4"),
                    guide = F) +
  theme_minimal() +
  facet_wrap(~species, ncol = 1) +
  coord_flip()
```

As an additional evaluation of the independent variables, a MANOVA test is applied on the four continuous variables along with year, which is defined as numeric. The categorical variables are not applicable for the MANOVA test. The results show a high significance for the four continuous variables while also indicating the year variable as not significant. These results confirm previous understanding of the independent variables.

```{r warning=F,message=F}
# MANOVA test
manova_res <- manova(cbind(bill_length_mm,bill_depth_mm,
                           flipper_length_mm,body_mass_g,year) ~ species, 
                     data = penguins)
summary.aov(manova_res)
```

\newpage

# Linear Discriminant Analysis (LDA)

Linear discriminant analysis is a classification method that separates classes through linear directions, or linear discriminants. The linear directions are derived as linear combinations of the predictor variables. As outlined above, LDA assumes the feature variables come from multivariate normal distributions and each one continuous. The different classes should also have class-specific means and equal variance/covariance. LDA does not handle categorical data well.

To prepare the data for the LDA model, the observations with missing data are removed from the dataset. Next, the categorical variables sex and year are removed. Based on the exploratory data analysis, neither variable appears to distinguish one species from another. Despite LDA not handling categorical data well, I chose to leave the variable $island$ in the dataset in an initial trial not included in this report.

In preparation of evaluating the model's accuracy, the penguins dataset is split into training and set partitions. Finally, the training and test datasets are transformed through a preprocessing step to normalize the data. Given the different range and distribution of the independent variable values, particularly the $body\_mass\_g$ variable, the normalization ensures each variable will be weighted based on predictive ability and not based on initial measurement value.

```{r warning=F,message=F,eval=T}
# Load the data
data("penguins")

# Only complete entries
penguins <- na.omit(penguins)

# Remove 'year' and 'sex' feature
# Apparently leaving 'island' in for LDA improves the model
drops <- c("year", "sex")
penguins <- penguins[ , !(names(penguins) %in% drops)]

#Split the data into training (75%) and test set (25%)
set.seed(123)
training.samples <- penguins$species %>%
  createDataPartition(p = 0.75, list=FALSE)
train.data <- penguins[training.samples, ]
test.data <- penguins[-training.samples, ]

#2. Normalize the data. Categorial variables are automatically ignored from normalizing
# Estimate preprocessing parameters
preproc.param <- train.data %>%
  preProcess(method = c("center", "scale"))

# Transform the data using the estimated parameters
train.transformed <- preproc.param %>% predict(train.data)
test.transformed <- preproc.param %>% predict(test.data)

```

Based on the exploratory data analysis, the three variables selected for the LDA model (and the two subsequent models) are $bill\_length\_mm$, $flipper\_length\_mm$ and $bill\_depth\_mm$. As the $body\_mass\_g$ variable was highly correlated with $bill\_length\_mm$ and $flipper\_length\_mm$, the variable was omitted from the model. All the categorical variables were also omitted, as LDA performs best on continuous variables.

```{r warning=F,message=F,eval=T}
# Fit the model
model.lda <- lda(species~bill_length_mm + flipper_length_mm + bill_depth_mm, 
                 data = train.transformed)

# Output Model
model.lda
```

When there are K classes, linear discriminant analysis can be viewed exactly in a K-1 dimensional plot.
With three classes in the species dependent variables, two linear discriminants are generated.

The plot of the LD1 and LD2 values on the two-dimensional plot shows the classification of the species in the 2D subspace.

```{r warning=F,message=F,eval=T}
# Plot
lda.data <- cbind(train.transformed, predict(model.lda)$x)
ggplot(lda.data, aes(LD1, LD2)) +
  geom_point(aes(color = species))
```

Now predict the species on the transformed test dataset.

```{r warning=F,message=F,eval=T}
# Make predictions
preds.lda <- model.lda %>% predict(test.transformed)

head(preds.lda$x, 3)

# Confusion matrix
table(preds.lda$class, test.transformed$species)

# Model accuracy
mean(preds.lda$class == test.transformed$species)
```

The confusion matrix indicates one incorrect prediction with an overall model accuracy of 98.78%.

The 2D subspace plot of LD1 and LD2 on the test dataset show a similar pattern to the scatterplot of the training data. The plot does show one outlier Chinstrap observation.

```{r warning=F,message=F,eval=T}

# Plot
lda.data <- cbind(test.transformed, preds.lda$x)
ggplot(lda.data, aes(LD1, LD2)) +
  geom_point(aes(color = species))

ldahist(data=preds.lda$x[,1], g=test.transformed$species)

ldahist(data=preds.lda$x[,2], g=test.transformed$species)
```

The bar plot for LD1 above shows a better performance in classifying among the three species, while the LD2 bar plot shows more overlap among the three species. These plots align with the proportion of trace from the initial model output. LD1 accounts for over 88% of the trace, while LD2 accounts for less than 12%.

The partition plots below from the $partimat$ function display the classification of each test observation for each combination of two independent variables. The plot with the lowest error rate is $bill\_length\_mm$ and $body\_mass\_g$.

```{r warning=F,message=F,eval=T}
partimat(species ~ bill_length_mm + bill_depth_mm + flipper_length_mm + body_mass_g, 
         data=test.transformed, method="lda")
```

\newpage

# Quadratic Discriminant Analysis (QDA)

Quadratic discriminant analysis, similar to linear discriminant analysis, also assumes a multivariate Gaussian distribution, but unlike LDA, QDA assumes each class has a unique covariance matrix. QDA draws the classification distinctions through quadratic decision boundaries, as the name implies, instead of the linear approach of LDA. To allow for even comparison among the three models, the same transformed training dataset is used for the QDA model.

```{r warning=F,message=F,eval=T}
# QDA
# Fit the model
model.qda <- qda(species~bill_length_mm + flipper_length_mm + bill_depth_mm, 
                 data = train.transformed)

# Output model results
model.qda
```

The model output for the QDA provides group means equal to the group means provided from the LDA model output. Thus, showing the similarity in behavior between the two model approaches. As the QDA model is quadratic, the model output does not contain coefficients for each independent variable as the LDA model does.

```{r warning=F,message=F,eval=T}
# Make predictions
preds.qda <- model.qda %>% predict(test.transformed)

# Confusion matrix
table(preds.qda$class, test.transformed$species)

# Model accuracy
mean(preds.qda$class == test.transformed$species)
```

The confusion matrix indicates two incorrect predictions with an overall model accuracy of 97.56%. Based on the textbook description of QDA, LDA typically outperforms QDA when relatively fewer training observations are used. Also, as the covariance matrix outlined in the exploratory data analysis, the assumptions are met for the LDA model approach. That being said, the difference in accuracy is based on a single additional incorrect prediction.

The below table indicates an error rate of 1.22% for LDA and an error rate of 2.44% for QDA.

```{r warning=F,message=F,eval=T}
test.transformed %>%
  summarise(lda.error = mean(preds.lda$class != test.transformed$species),
            qda.error = mean(preds.qda$class != test.transformed$species))
```

The partition plots below capture the quadratic nature of the decision boundaries.

```{r warning=F,message=F,eval=T}
partimat(species ~ bill_length_mm + bill_depth_mm + flipper_length_mm + body_mass_g, 
         data=test.transformed, method="qda")
```

\newpage

# Naive Bayes

The Naive Bayes classifier relies on Bayes theorem of probability. The naive Bayes classifier makes a simplifying assumption which is all predictor variables are conditionally independent of each other in regards to the dependent variable. For numeric features, the Naive Bayes approach makes an assumption that the numerical variables are normally distributed. Due to the assumption of conditional independence, the NB classifier can lead to biased posterior probabilities.

```{r warning=F,message=F,eval=T}
# Fitting the Naive Bayes model
model.nb <- naiveBayes(species~bill_length_mm + flipper_length_mm + bill_depth_mm, 
                       data=train.transformed)

# Output the model
model.nb
```

Interestingly enough, the conditional probabilities of the NB model match the group means for the LDA and QDA models, a good sign for the upcoming predictions.

```{r warning=F,message=F,eval=T}
# Prediction on the dataset
preds.nb <- predict(model.nb, test.transformed)
# Confusion matrix to check accuracy
table(preds.nb, test.transformed$species)

mean(preds.nb == test.transformed$species)
```

The confusion matrix indicates one incorrect prediction with an overall model accuracy of 98.78%. 

With the same conditional probabilities of the NB model as the group means of the LDA model, the predictions are the exact same. Each model contains one incorrect prediction of an Adelie penguin predicted as a Chinstrap.


### AUC Comparison

Give the three classifier models resulting in near identical group means and conditional probabilities, along with the near identical accuracy, the following area under the curve plots show results just short of 1.0.

```{r warning=F,message=F,eval=T}
# ROC curves

par(mfrow=c(2, 2))

preds.lda.num <- as.numeric(preds.lda$class)
roc.multi.lda <- multiclass.roc(test.transformed$species, preds.lda.num)
lda.auc <- auc(roc.multi.lda)
rs.lda <- roc.multi.lda[['rocs']]
plot.roc(rs.lda[[1]], main="LDA",
         xlim=c(1, 0), ylim=c(0, 1), add=FALSE, asp=NA)

preds.qda.num <- as.numeric(preds.qda$class)
roc.multi.qda <- multiclass.roc(test.transformed$species, preds.qda.num)
qda.auc <- auc(roc.multi.qda)
rs.qda <- roc.multi.qda[['rocs']]
plot.roc(rs.qda[[1]], main="QDA",
         xlim=c(1, 0), ylim=c(0, 1), add=FALSE, asp=NA)

preds.nb.num <- as.numeric(preds.nb)
roc.multi.nb <- multiclass.roc(test.transformed$species, preds.nb.num)
nb.auc <- auc(roc.multi.nb)
rs.nb <- roc.multi.nb[['rocs']]
plot.roc(rs.nb[[1]], main="Naive Bayes",
         xlim=c(1, 0), ylim=c(0, 1), add=FALSE, asp=NA)
```

Area under the curve results:

LDA: `r lda.auc`; QDA: `r qda.auc`; Naive Bayes: `r nb.auc`

# Conclusion

Overall, the model fit and accuracy of the three classifier models proved near identical. Given the standard training and test approach to the models, each model produced an accuracy near 1.0. The normalization of the data played a key factor in ensuring the predictor variables received equal weight in the discriminant analysis classifiers. The LDA model outperformed the QDA model as the data assumptions more closely fit the LDA model assumption of multivariate Gaussian distribution of the predictor variables within each class. The QDA model suffered a small amount as the covariance was not unique across the species dependent variable. The Naive Bayes classifier performed just as well as the LDA classifier even though the conditional independence was not met by the predictor variables. As the variables are based on penguin physical measurements, the measurements are bound to be correlated. The assignment presented a good exercise in experimenting with different, yet similar classifiers for a sample dataset. I would expect the QDA and Naive Bayes classifiers to outperform the LDA classifier if the dataset did contain a less correlated set of predictor variables.

# References
