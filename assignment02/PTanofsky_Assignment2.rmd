---
title: "DATA 622 Assignment 2"
subtitle: "CUNY: Spring 2021"
author: "Philip Tanofsky"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: pdf_document
---

# Introduction

The purpose of this project is to apply generative model approaches to the Palmer Penguin data set available at https://allisonhorst.github.io/palmerpenguins/articles/intro.html. The first approach performs linear discriminant analysis (LDA) on the dataset in order to predict the species of the penguin subjects. The second approach performs a quadratic discriminant analysis in order to predict the species of penguin subjects. The final approach uses the Naive Bayes modeling approach to also predict the species of the penguin subjects. The exploratory data analysis informs the decisions of the predictor variables included for each generative model. A final comparison of the models are presented in order to compare the accuracy of each.

```{r warning=F, message=F}
# Import required R libraries
library(palmerpenguins)
library(tidyverse)
library(caret)
library(MASS)
library(ggplot2)
library(mvtnorm)
library(e1071)
library(klaR)
theme_set(theme_classic())
```

Initial Data Inspection

```{r warning=F,message=F}
ds <- penguins

head(ds)

summary(ds)

dim(ds)

glimpse(ds)

visdat::vis_dat(ds)
```

# Exploratory Data Analysis

For linear discriminant analysis, two assumptions are made about the data. One, the predictors are normally distributed, which means the data follows a Gaussian distribution for each class. Two, the classes have class-specific means but also have equal variance and covariance

First step, confirm multivariate normal distribution. A density plot of the four continuous variables by species indicates the normal distribution for the class-specific plots.

```{r warning=F,message=F}
# Overlayed density plots
featurePlot(x = penguins[, 3:6],
            y = penguins$species,
            plot = "density",
            # Pass in options to xyplot() to
            # make it prettier
            scales = list(x = list(relation="free"),
                          y = list(relation="free")),
            adjust = 1.5,
            pch = "|",
            layout = c(2, 2),
            auto.key = list(columns = 3))
```

The variable $flipper_length_mm$ shows the clearest example of normal distribution by species class. The four density plots also indicate common evaluations between the Adelie and Chinstrap species for the independent variables flipper_length_mm, body_mass_g, and bill_depth_mm. The remaining continuous variable, bill_length_mm, shows an overlap between the Chinstrap and Gentoo species.

The scatterplot matrix of the continuous variables indicates the relationships between the independent variables for each of the three penguin species.

```{r warning=F,message=F}
# Use featurePlot
# https://topepo.github.io/caret/visualizations.html

# Scatterplot
featurePlot(x = penguins[, 3:6],
            y = penguins$species,
            plot = "pairs",
            # Add a key at the top
            auto.key = list(columns = 3))
```

The independent variable $bill_length_mm$ stands out by providing a clear distinction between the three penguin species when compared with any of the other three independent variables. As seen in the above scatterplot, when using any two of the other three independent variables, the plot results in a clear overlap of the Adelie and Chinstrap species, an expected result given the prior density plots.

So far, the independent variable $bill_length_mm$ is a prime candidate to be included in the generative models. The key will be identifying which of the other variables will provide additional significance to the model.

```{r warning=F,message=F}
featurePlot(x = penguins[, 3:6], 
            y = penguins$species, 
            plot = "box", 
            ## Pass in options to bwplot() 
            scales = list(y = list(relation="free"),
                          x = list(rot = 90)),  
            layout = c(2,2), 
            auto.key = list(columns = 2))
```

With the first assumption confirmed, the second assumption is to confirm the similar covariance across the species classes. The following Covariance checks
```{r warning=F,message=F}
# Compute covariance matrix
#cov_mat <- cov(penguins[,3:6],  use = "complete.obs")
#round(cov_mat, 2)

# Covariance matrix
p_g <- penguins %>% filter(species == 'Gentoo')
cov_mat <- cov(p_g[,3:6],  use = "complete.obs")
round(cov_mat, 2)

p_a <- penguins %>% filter(species == 'Adelie')
cov_mat <- cov(p_a[,3:6],  use = "complete.obs")
round(cov_mat, 2)

p_c <- penguins %>% filter(species == 'Chinstrap')
cov_mat <- cov(p_c[,3:6],  use = "complete.obs")
round(cov_mat, 2)

# Means
p_a[,3:6] %>% summarise_each(funs( mean( .,na.rm = TRUE)))
p_g[,3:6] %>% summarise_each(funs( mean( .,na.rm = TRUE)))
p_c[,3:6] %>% summarise_each(funs( mean( .,na.rm = TRUE)))
```

Assessing the mean of each continuous independent variable for each species class, the variable $bill\_depth\_mm$ highlights the least difference in mean values of four variables. In fact, the difference in mean for Adelie and Chinstrap is one tenth of the measurement.

Comparing the variance of each continuous independent variable across the three species classes, $body\_mass\_g$ shows the divergence in the variance evaluation, particularly for the Gentoo species. Then again, this variable is a weight measured in grams, so perhaps dividing each value by 1000 to measure in kilograms would make the variance seems less divergent. The prior density plot does show the wider distribution among Gentoo species for $body\_mass\_g$.

Highlighting the covariance, in which a low number indicates a weak relationship, $bill\_length\_mm$ and $bill\_depth\_mm$. Two variables, $bill\_depth\_mm$ and $flipper\_length\_mm$, also show a comparatively low covariance. $bill\_length\_mm$ and $flipper\_length\_mm$ indicates a covariance higher than the aforementioned pairs, but the resulting values across the species classes are much better than the not listed variable pairs.

## Correlation matrix

Based on the covariance matrix, the correlation matrix should confirm the variable relationships as previously noted. Again, $bill\_length\_mm$ and $bill\_depth\_mm$ show the least correlation. $body\_mass\_g$ and $flipper\_length\_mm$ have a high correlation.

```{r warning=F,message=F}
# Compute correlation matrix
cor_mat <- cor(penguins[,3:6],  use = "complete.obs")
round(cor_mat, 2)

library(corrplot)
corrplot(cor_mat, type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45)

```

```{r warning=F,message=F,eval=F}
# Plots of individual variables
#http://www.sthda.com/english/articles/32-r-graphics-essentials/133-plot-one-variable-frequency-graph-density-distribution-and-more/


# Change density plot fill colors by groups
p <- ggplot(penguins, aes(x=bill_length_mm, fill=species)) +
  geom_density(alpha=0.4)

p

a <- penguins %>% 
      filter(species == 'Gentoo') %>%
      ggplot(aes(x = bill_length_mm))

#a <- ggplot(penguins, aes(x = bill_length_mm))

a + geom_histogram(bins = 30, color = "black", fill = "gray") +
  geom_vline(aes(xintercept = mean(bill_length_mm)), 
             linetype = "dashed", size = 0.6)

b <- ggplot(penguins, aes(x = bill_depth_mm))

b + geom_histogram(bins = 30, color = "black", fill = "gray") +
  geom_vline(aes(xintercept = mean(bill_depth_mm)), 
             linetype = "dashed", size = 0.6)

c <- ggplot(penguins, aes(x = flipper_length_mm))

c + geom_histogram(bins = 30, color = "black", fill = "gray") +
  geom_vline(aes(xintercept = mean(flipper_length_mm)), 
             linetype = "dashed", size = 0.6)

d <- ggplot(penguins, aes(x = body_mass_g))

d + geom_histogram(bins = 30, color = "black", fill = "gray") +
  geom_vline(aes(xintercept = mean(body_mass_g)), 
             linetype = "dashed", size = 0.6)
```


# LDA: Linear Discriminant Analysis

LDA does not handle categorical data well.

LDA assumes the feature variables come from multivariate normal distribution, all of them continuous

http://www.sthda.com/english/articles/36-classification-methods-essentials/146-discriminant-analysis-essentials-in-r/

LDA assumes the predictors are normally distributed (Gaussian distribution) and that the different classes have class-specific means and equal variance/covariance

Make sure each variable is normally distributed

https://web.stanford.edu/class/stats202/notes/Classification/LDA.html
That is, within each class the features have multivariate normal distribution with center depending on the class and common covariance

In the covariance matrix in the output, the off-diagonal elements contain the covariances of each pair of variables. The diagonal elements of the covariance matrix contain the variances of each variable. The variance measures how much the data are scattered about the mean.

bill_depth, bill_length, body_mass

```{r warning=F,message=F,eval=T}
# Load the data
data("penguins")

# Only complete entries
penguins <- na.omit(penguins)

# Remove 'year' and 'sex feature
# Apparently leaving 'island' in for LDA improves the model
drops <- c("year", "sex")
penguins <- penguins[ , !(names(penguins) %in% drops)]

#Split the data into training (75%) and test set (25%)
set.seed(123)
training.samples <- penguins$species %>%
  createDataPartition(p = 0.75, list=FALSE)
train.data <- penguins[training.samples, ]
test.data <- penguins[-training.samples, ]

#2. Normalize the data. Categorial variables are automatically ignored from normalizing
# Estimate preprocessing parameters
preproc.param <- train.data %>%
  preProcess(method = c("center", "scale"))

# Transform the data using the estimated parameters
train.transformed <- preproc.param %>% predict(train.data)
test.transformed <- preproc.param %>% predict(test.data)

```

Focus on normal distributions

If n is small and the distribution of the predictors X is approximately normal in each of the classes, the LD model is more stable than logistic regression

Correlation will cause a line in the Gaussian density plot

When there are K classes, linear discriminant analysis can be viewed exactly in a K-1 dimensional plot.
Measuring which centroid is the closest. Distance in the subspace


```{r warning=F,message=F,eval=T}
# Fit the model
model <- lda(species~bill_length_mm + flipper_length_mm, data = train.transformed)
# Make predictions
predictions <- model %>% predict(test.transformed)

# Confusion matrix
table(predictions$class, test.transformed$species)

# Model accuracy
mean(predictions$class == test.transformed$species)

# Output Model
model

# Display model
plot(model)

names(predictions)

# Predicted classes
head(predictions$class, 6)
# Predicted probabilities of class membership
head(predictions$posterior, 6)
# Linear discriminants
head(predictions$x, 3)

# Plot
lda.data <- cbind(train.transformed, predict(model)$x)
ggplot(lda.data, aes(LD1, LD2)) +
  geom_point(aes(color = species))

# From: https://rpubs.com/Nolan/298913
plot(model, dimen = 1, type = "b")


partimat(species ~ bill_length_mm + bill_depth_mm + flipper_length_mm + body_mass_g, data=train.transformed, method="lda")

# Model accuracy
mean(predictions$class==test.transformed$species)

sum(predictions$posterior[ ,1] >= .5)
```

```{r warning=F,message=F,eval=T}
# QDA

# Remove 'island' feature as it was causing rank deficiency in group Chinstrap
#drops <- c("flipper_length_mm", "body_mass_g", "island")
drops <- c("island")
train.transformed <- train.transformed[ , !(names(train.transformed) %in% drops)]

# Fit the model
model <- qda(species~., data = train.transformed)

# Output model results
model

partimat(species ~ bill_length_mm + bill_depth_mm + flipper_length_mm + body_mass_g, data=train.transformed, method="qda")

# Make predictions
predictions <- model %>% predict(test.transformed)

# Confusion matrix
table(predictions$class, test.transformed$species)

# Model accuracy
mean(predictions$class == test.transformed$species)

# Plot


```

https://www.geeksforgeeks.org/linear-discriminant-analysis-in-r-programming/


# QDA: Quadratic Discriminant Analysis

Same link as above

QDA: works well with fewer features, that's when NB works well, works with higher number of features

mixed features can be used for NB

# NB: Naive Bayes

https://www.r-bloggers.com/2018/01/understanding-naive-bayes-classifier-using-r/
```{r warning=F,message=F,eval=T}
# Modified for the penguin data

# Fitting the Naive Bayes model
nbm <- naiveBayes(species~., data=train.transformed)

# Output the model
nbm

plot.NaiveBayes(nbm)

# Prediction on the dataset
nb_predictions <- predict(nbm, test.transformed)
# Confusion matrix to check accuracy
table(nb_predictions, test.transformed$species)

mean(nb_predictions == test.transformed$species)

# Getting started with Naive Bayes in mlr
library(mlr)

# Create a classification task for learning on Titantic Dataset and specify the target feature
task <- makeClassifTask(data = train.transformed, target="species")

# Initialize the Naive Bayes classifier
selected_model <- makeLearner("classif.naiveBayes")

# Train the model
nb_mlr <- train(selected_model, task)

# Read the model learned
nb_mlr$learner.model

# Predict on the dataset without passing the target feature
predictions_mlr <- as.data.frame(predict(nb_mlr, newdata = test.transformed))

# Confusion matrix to check accuracy
table(predictions_mlr[,1], test.transformed$species)

mean(predictions_mlr[,1] == test.transformed$species)
```



https://www.geeksforgeeks.org/naive-bayes-classifier-in-r-programming/

Palmer Penguins citation

# ==== Prompt =====

```{r eval=F}
Homework # 2 (Generative Models) (100 points) Due on March 12, 11:59pm EST
We will be working with the Penguin dataset again as we did for Homework #1. Please use "Species" as your target variable. For this assignment, you may want to drop/ignore the variable "year".
Using the target variable, Species, please conduct:
a. LinearDiscriminantAnalysis(30points):
a. Youwanttoevaluateallthe'features'ordependentvariablesandsee what should be in your model. Please comment on your choices.
b. Justasuggestion:YoumightwanttoconsiderexploringfeaturePlot on the caret package. Basically, you look at each of the features/dependent variables and see how they are different based on species. Simply eye-balling this might give you an idea about which would be strong 'classifiers' (aka predictors).
c. Fit your LDA model using whatever predictor variables you deem appropriate. Feel free to split the data into training and test sets before fitting the model.
d. Lookatthefitstatistics/accuracyrates.
b. QuadraticDiscriminantAnalysis(30points)
a. Samestepsasabovetoconsider
c. Naive Bayes (30 points)
a. Samestepsasabovetoconsider
d. Commentonthemodelsfits/strength/weakness/accuracyforallthesethree models that you worked with. (10 points)
```